{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imutils in c:\\python311\\lib\\site-packages (0.5.4)\n",
      "Requirement already satisfied: cmake in c:\\python311\\lib\\site-packages (3.28.3)\n",
      "Requirement already satisfied: dlib in c:\\python311\\lib\\site-packages (19.24.2)\n",
      "Requirement already satisfied: face_recognition in c:\\python311\\lib\\site-packages (1.3.0)\n",
      "Requirement already satisfied: numpy in c:\\python311\\lib\\site-packages (1.26.4)\n",
      "Requirement already satisfied: pandas in c:\\python311\\lib\\site-packages (1.5.3)\n",
      "Requirement already satisfied: scikit-learn in c:\\python311\\lib\\site-packages (1.2.1)\n",
      "Requirement already satisfied: opencv-contrib-python-headless in c:\\python311\\lib\\site-packages (4.9.0.80)\n",
      "Requirement already satisfied: pillow in c:\\python311\\lib\\site-packages (10.2.0)\n",
      "Requirement already satisfied: firebase_admin in c:\\python311\\lib\\site-packages (6.4.0)\n",
      "Requirement already satisfied: google-cloud-storage in c:\\python311\\lib\\site-packages (2.14.0)\n",
      "Requirement already satisfied: google-cloud-bigquery in c:\\python311\\lib\\site-packages (3.17.2)\n",
      "Requirement already satisfied: google-cloud-aiplatform in c:\\python311\\lib\\site-packages (1.41.0)\n",
      "Requirement already satisfied: google-cloud-pipeline-components in c:\\python311\\lib\\site-packages (2.9.0)\n",
      "Requirement already satisfied: kfp in c:\\python311\\lib\\site-packages (2.6.0)\n",
      "Collecting logger\n",
      "  Downloading logger-1.4.tar.gz (1.2 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: face-recognition-models>=0.3.0 in c:\\python311\\lib\\site-packages (from face_recognition) (0.3.0)\n",
      "Requirement already satisfied: Click>=6.0 in c:\\python311\\lib\\site-packages (from face_recognition) (8.1.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\parth\\appdata\\roaming\\python\\python311\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\python311\\lib\\site-packages (from pandas) (2022.7.1)\n",
      "Requirement already satisfied: scipy>=1.3.2 in c:\\python311\\lib\\site-packages (from scikit-learn) (1.10.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\python311\\lib\\site-packages (from scikit-learn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\python311\\lib\\site-packages (from scikit-learn) (3.1.0)\n",
      "Requirement already satisfied: cachecontrol>=0.12.6 in c:\\python311\\lib\\site-packages (from firebase_admin) (0.14.0)\n",
      "Requirement already satisfied: google-api-python-client>=1.7.8 in c:\\python311\\lib\\site-packages (from firebase_admin) (2.117.0)\n",
      "Requirement already satisfied: pyjwt>=2.5.0 in c:\\python311\\lib\\site-packages (from pyjwt[crypto]>=2.5.0->firebase_admin) (2.8.0)\n",
      "Requirement already satisfied: google-api-core<3.0.0dev,>=1.22.1 in c:\\python311\\lib\\site-packages (from google-api-core[grpc]<3.0.0dev,>=1.22.1; platform_python_implementation != \"PyPy\"->firebase_admin) (2.17.0)\n",
      "Requirement already satisfied: google-cloud-firestore>=2.9.1 in c:\\python311\\lib\\site-packages (from firebase_admin) (2.14.0)\n",
      "Requirement already satisfied: google-auth<3.0dev,>=2.23.3 in c:\\python311\\lib\\site-packages (from google-cloud-storage) (2.27.0)\n",
      "Requirement already satisfied: google-cloud-core<3.0dev,>=2.3.0 in c:\\python311\\lib\\site-packages (from google-cloud-storage) (2.4.1)\n",
      "Requirement already satisfied: google-resumable-media>=2.6.0 in c:\\python311\\lib\\site-packages (from google-cloud-storage) (2.7.0)\n",
      "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in c:\\python311\\lib\\site-packages (from google-cloud-storage) (2.31.0)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in c:\\python311\\lib\\site-packages (from google-cloud-storage) (1.5.0)\n",
      "Requirement already satisfied: packaging>=20.0.0 in c:\\python311\\lib\\site-packages (from google-cloud-bigquery) (23.2)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.0 in c:\\python311\\lib\\site-packages (from google-cloud-aiplatform) (1.23.0)\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5 in c:\\python311\\lib\\site-packages (from google-cloud-aiplatform) (4.22.0)\n",
      "Requirement already satisfied: google-cloud-resource-manager<3.0.0dev,>=1.3.3 in c:\\python311\\lib\\site-packages (from google-cloud-aiplatform) (1.12.1)\n",
      "Requirement already satisfied: shapely<3.0.0dev in c:\\python311\\lib\\site-packages (from google-cloud-aiplatform) (2.0.2)\n",
      "Requirement already satisfied: Jinja2==3.1.2 in c:\\python311\\lib\\site-packages (from google-cloud-pipeline-components) (3.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\python311\\lib\\site-packages (from Jinja2==3.1.2->google-cloud-pipeline-components) (2.1.2)\n",
      "Requirement already satisfied: docstring-parser<1,>=0.7.3 in c:\\python311\\lib\\site-packages (from kfp) (0.15)\n",
      "Requirement already satisfied: kfp-pipeline-spec==0.3.0 in c:\\python311\\lib\\site-packages (from kfp) (0.3.0)\n",
      "Requirement already satisfied: kfp-server-api<2.1.0,>=2.0.0 in c:\\python311\\lib\\site-packages (from kfp) (2.0.5)\n",
      "Requirement already satisfied: kubernetes<27,>=8.0.0 in c:\\python311\\lib\\site-packages (from kfp) (26.1.0)\n",
      "Requirement already satisfied: PyYAML<7,>=5.3 in c:\\python311\\lib\\site-packages (from kfp) (6.0)\n",
      "Requirement already satisfied: requests-toolbelt<1,>=0.8.0 in c:\\python311\\lib\\site-packages (from kfp) (0.10.1)\n",
      "Requirement already satisfied: tabulate<1,>=0.8.6 in c:\\python311\\lib\\site-packages (from kfp) (0.9.0)\n",
      "Requirement already satisfied: urllib3<2.0.0 in c:\\python311\\lib\\site-packages (from kfp) (1.26.18)\n",
      "Requirement already satisfied: msgpack<2.0.0,>=0.5.2 in c:\\python311\\lib\\site-packages (from cachecontrol>=0.12.6->firebase_admin) (1.0.7)\n",
      "Requirement already satisfied: colorama in c:\\users\\parth\\appdata\\roaming\\python\\python311\\site-packages (from Click>=6.0->face_recognition) (0.4.6)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in c:\\python311\\lib\\site-packages (from google-api-core<3.0.0dev,>=1.22.1->google-api-core[grpc]<3.0.0dev,>=1.22.1; platform_python_implementation != \"PyPy\"->firebase_admin) (1.62.0)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in c:\\python311\\lib\\site-packages (from google-api-core[grpc]<3.0.0dev,>=1.22.1; platform_python_implementation != \"PyPy\"->firebase_admin) (1.60.1)\n",
      "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in c:\\python311\\lib\\site-packages (from google-api-core[grpc]<3.0.0dev,>=1.22.1; platform_python_implementation != \"PyPy\"->firebase_admin) (1.60.1)\n",
      "Requirement already satisfied: httplib2<1.dev0,>=0.15.0 in c:\\python311\\lib\\site-packages (from google-api-python-client>=1.7.8->firebase_admin) (0.22.0)\n",
      "Requirement already satisfied: google-auth-httplib2>=0.1.0 in c:\\python311\\lib\\site-packages (from google-api-python-client>=1.7.8->firebase_admin) (0.2.0)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in c:\\python311\\lib\\site-packages (from google-api-python-client>=1.7.8->firebase_admin) (4.1.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\python311\\lib\\site-packages (from google-auth<3.0dev,>=2.23.3->google-cloud-storage) (5.3.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\python311\\lib\\site-packages (from google-auth<3.0dev,>=2.23.3->google-cloud-storage) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\python311\\lib\\site-packages (from google-auth<3.0dev,>=2.23.3->google-cloud-storage) (4.9)\n",
      "Requirement already satisfied: grpc-google-iam-v1<1.0.0dev,>=0.12.4 in c:\\python311\\lib\\site-packages (from google-cloud-resource-manager<3.0.0dev,>=1.3.3->google-cloud-aiplatform) (0.13.0)\n",
      "Requirement already satisfied: six>=1.10 in c:\\python311\\lib\\site-packages (from kfp-server-api<2.1.0,>=2.0.0->kfp) (1.16.0)\n",
      "Requirement already satisfied: certifi in c:\\python311\\lib\\site-packages (from kfp-server-api<2.1.0,>=2.0.0->kfp) (2024.2.2)\n",
      "Requirement already satisfied: setuptools>=21.0.0 in c:\\python311\\lib\\site-packages (from kubernetes<27,>=8.0.0->kfp) (65.5.0)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in c:\\python311\\lib\\site-packages (from kubernetes<27,>=8.0.0->kfp) (1.5.1)\n",
      "Requirement already satisfied: requests-oauthlib in c:\\python311\\lib\\site-packages (from kubernetes<27,>=8.0.0->kfp) (1.3.1)\n",
      "Requirement already satisfied: cryptography>=3.4.0 in c:\\python311\\lib\\site-packages (from pyjwt[crypto]>=2.5.0->firebase_admin) (42.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\python311\\lib\\site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\python311\\lib\\site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (3.4)\n",
      "Requirement already satisfied: cffi>=1.12 in c:\\python311\\lib\\site-packages (from cryptography>=3.4.0->pyjwt[crypto]>=2.5.0->firebase_admin) (1.15.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in c:\\python311\\lib\\site-packages (from httplib2<1.dev0,>=0.15.0->google-api-python-client>=1.7.8->firebase_admin) (3.0.9)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\python311\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0dev,>=2.23.3->google-cloud-storage) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\python311\\lib\\site-packages (from requests-oauthlib->kubernetes<27,>=8.0.0->kfp) (3.2.2)\n",
      "Requirement already satisfied: pycparser in c:\\python311\\lib\\site-packages (from cffi>=1.12->cryptography>=3.4.0->pyjwt[crypto]>=2.5.0->firebase_admin) (2.21)\n",
      "Building wheels for collected packages: logger\n",
      "  Building wheel for logger (setup.py): started\n",
      "  Building wheel for logger (setup.py): finished with status 'done'\n",
      "  Created wheel for logger: filename=logger-1.4-py3-none-any.whl size=1761 sha256=4d83407eb9af8f07cf5539095ee16e01157d10292ae4b02280c0789d74051b6d\n",
      "  Stored in directory: c:\\users\\parth\\appdata\\local\\pip\\cache\\wheels\\cd\\1d\\c8\\f1361043ff09fd3c9a747b199e8e37bd716bacf0843bbdb68f\n",
      "Successfully built logger\n",
      "Installing collected packages: logger\n",
      "Successfully installed logger-1.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEPRECATION: Loading egg at c:\\python311\\lib\\site-packages\\mask_rcnn-2.1-py3.11.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation.. Discussion can be found at https://github.com/pypa/pip/issues/12330\n"
     ]
    }
   ],
   "source": [
    "%pip install imutils cmake dlib face_recognition numpy pandas scikit-learn opencv-contrib-python-headless pillow firebase_admin google-cloud-storage google-cloud-bigquery google-cloud-aiplatform google-cloud-pipeline-components kfp logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary modules\n",
    "\n",
    "import os\n",
    "from google.cloud import aiplatform\n",
    "\n",
    "from kfp.dsl import pipeline, component\n",
    "from kfp import compiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ID = \"plenary-truck-411220\"\n",
    "PIPELINE_ROOT = \"gs://faces_for_clusters\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = \"../keys/detectionKey.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "aiplatform.init(project=PROJECT_ID, location=\"asia-south1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "@component(base_image=\"python:3.10\", packages_to_install=[\"numpy==1.23.5\", \"opencv-contrib-python-headless==4.9.0.80\", \"imutils==0.5.4\", \"db-dtypes==1.2.0\", \"scikit-learn==1.4.1.post1\", \"pillow==10.2.0\", \"build==1.0.3\", \"cmake==3.28.3\", \"dlib==19.24.2\", \"face-recognition==1.3.0\", \"logger==1.4\", \"requests==2.31.0\", \"pandas==2.2.0\", \"google-cloud-storage==2.14.0\", \"google-cloud-bigquery==3.17.2\", \"kfp==2.6.0\"])\n",
    "def fetch_cropped_imgs_and_clustering()->bool:\n",
    "    \n",
    "    from google.cloud import bigquery, storage\n",
    "    import cv2\n",
    "    import numpy as np\n",
    "    from PIL import Image\n",
    "    import dlib\n",
    "    import os\n",
    "    import logging\n",
    "    import traceback\n",
    "    import requests\n",
    "    from imutils import paths, build_montages\n",
    "    import face_recognition\n",
    "    from pandas import DataFrame\n",
    "    from sklearn.cluster import DBSCAN\n",
    "\n",
    "    logging.basicConfig(level=logging.DEBUG)\n",
    "\n",
    "    logger = logging.getLogger(__name__)\n",
    "\n",
    "    def move_image(image: cv2.typing.MatLike, id: int, labelID: int) -> None:\n",
    "        \"\"\"\n",
    "        Move the image to a labeled directory.\n",
    "\n",
    "        Parameters:\n",
    "        - image (cv2.typing.MatLike): The image data.\n",
    "        - id (int): The identifier for the image.\n",
    "        - labelID (int): The label identifier for the image.\n",
    "\n",
    "        Returns:\n",
    "        - None\n",
    "        \"\"\"\n",
    "        try:\n",
    "            path = os.getcwd() + '/label' + str(labelID)\n",
    "\n",
    "            if os.path.exists(path) == False:\n",
    "                os.mkdir(path)\n",
    "\n",
    "            filename = str(id) + '.jpg'\n",
    "\n",
    "            cv2.imwrite(os.path.join(path, filename), image)\n",
    "        except Exception as e:\n",
    "            logger.critical(f\"An error occurred: {str(e)}\")\n",
    "\n",
    "\n",
    "    def load_img(path:str) -> cv2.typing.MatLike:\n",
    "        img = cv2.imread(path)\n",
    "        return img\n",
    "\n",
    "\n",
    "    def draw_predict(\n",
    "        frame:cv2.typing.MatLike, \n",
    "        left:int, \n",
    "        top:int, \n",
    "        right:int, \n",
    "        bottom:int\n",
    "        )->None:\n",
    "        cv2.rectangle(\n",
    "            frame, \n",
    "            (left, top), \n",
    "            (right, bottom), \n",
    "            (0, 0, 255), \n",
    "            3\n",
    "        )\n",
    "\n",
    "\n",
    "    def get_eyes_nose_dlib(shape):\n",
    "        nose = shape[4][1]\n",
    "        left_eye_x = int(shape[3][1][0] + shape[2][1][0]) // 2\n",
    "        left_eye_y = int(shape[3][1][1] + shape[2][1][1]) // 2\n",
    "        right_eyes_x = int(shape[1][1][0] + shape[0][1][0]) // 2\n",
    "        right_eyes_y = int(shape[1][1][1] + shape[0][1][1]) // 2\n",
    "        return nose, (left_eye_x, left_eye_y), (right_eyes_x, right_eyes_y)\n",
    "\n",
    "\n",
    "    def get_eyes_nose(eyes, nose):\n",
    "        left_eye_x = int(eyes[0][0] + eyes[0][2] / 2)\n",
    "        left_eye_y = int(eyes[0][1] + eyes[0][3] / 2)\n",
    "        right_eye_x = int(eyes[1][0] + eyes[1][2] / 2)\n",
    "        right_eye_y = int(eyes[1][1] + eyes[1][3] / 2)\n",
    "        nose_x = int(nose[0][0] + nose[0][2] / 2)\n",
    "        nose_y = int(nose[0][1] + nose[0][3] / 2)\n",
    "\n",
    "        return (nose_x, nose_y), (right_eye_x, right_eye_y), (left_eye_x, left_eye_y)\n",
    "\n",
    "\n",
    "    def rotate_point(origin, point, angle):\n",
    "        ox, oy = origin\n",
    "        px, py = point\n",
    "\n",
    "        qx = ox + np.cos(angle) * (px - ox) - np.sin(angle) * (py - oy)\n",
    "        qy = oy + np.sin(angle) * (px - ox) + np.cos(angle) * (py - oy)\n",
    "        return qx, qy\n",
    "\n",
    "\n",
    "    def is_between(point1, point2, point3, extra_point):\n",
    "        c1 = (point2[0] - point1[0]) * (extra_point[1] - point1[1]) - (point2[1] - point1[1]) * (extra_point[0] - point1[0])\n",
    "        c2 = (point3[0] - point2[0]) * (extra_point[1] - point2[1]) - (point3[1] - point2[1]) * (extra_point[0] - point2[0])\n",
    "        c3 = (point1[0] - point3[0]) * (extra_point[1] - point3[1]) - (point1[1] - point3[1]) * (extra_point[0] - point3[0])\n",
    "        if (c1 < 0 and c2 < 0 and c3 < 0) or (c1 > 0 and c2 > 0 and c3 > 0):\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "\n",
    "    def distance(a, b):\n",
    "        return np.sqrt((a[0] - b[0]) ** 2 + (a[1] - b[1]) ** 2)\n",
    "\n",
    "\n",
    "    def cosine_formula(length_line1, length_line2, length_line3):\n",
    "        cos_a = -(length_line3 ** 2 - length_line2 ** 2 - length_line1 ** 2) / (2 * length_line2 * length_line1)\n",
    "        return cos_a\n",
    "\n",
    "\n",
    "    def show_img(img):\n",
    "        while True:\n",
    "            cv2.imshow('face_alignment_app', img)\n",
    "            c = cv2.waitKey(1)\n",
    "            if c == 27:\n",
    "                break\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "    def shape_to_normal(shape):\n",
    "        shape_normal = []\n",
    "        for i in range(0, 5):\n",
    "            shape_normal.append((i, (shape.part(i).x, shape.part(i).y)))\n",
    "        return shape_normal\n",
    "\n",
    "\n",
    "    def rotate_opencv(img, nose_center, angle):\n",
    "        M = cv2.getRotationMatrix2D(nose_center, angle, 1)\n",
    "        rotated = cv2.warpAffine(img, M, (img.shape[1], img.shape[0]), flags=cv2.INTER_CUBIC)\n",
    "        return rotated\n",
    "\n",
    "\n",
    "    def rotation_detection_dlib(img, mode, show=False):\n",
    "        detector = dlib.get_frontal_face_detector()#type:ignore\n",
    "        predictor = dlib.shape_predictor('shape_predictor_5_face_landmarks.dat')#type:ignore\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        rects = detector(gray, 0)\n",
    "        if len(rects) > 0:\n",
    "            for rect in rects:\n",
    "                x = rect.left()\n",
    "                y = rect.top()\n",
    "                w = rect.right()\n",
    "                h = rect.bottom()\n",
    "                shape = predictor(gray, rect)\n",
    "                shape = shape_to_normal(shape)\n",
    "                nose, left_eye, right_eye = get_eyes_nose_dlib(shape)\n",
    "                center_of_forehead = ((left_eye[0] + right_eye[0]) // 2, (left_eye[1] + right_eye[1]) // 2)\n",
    "                center_pred = (int((x + w) / 2), int((y + y) / 2))\n",
    "                length_line1 = distance(center_of_forehead, nose)\n",
    "                length_line2 = distance(center_pred, nose)\n",
    "                length_line3 = distance(center_pred, center_of_forehead)\n",
    "                cos_a = cosine_formula(length_line1, length_line2, length_line3)\n",
    "                angle = np.arccos(cos_a)\n",
    "                rotated_point = rotate_point(nose, center_of_forehead, angle)\n",
    "                rotated_point = (int(rotated_point[0]), int(rotated_point[1]))\n",
    "                if is_between(nose, center_of_forehead, center_pred, rotated_point):\n",
    "                    angle = np.degrees(-angle)\n",
    "                else:\n",
    "                    angle = np.degrees(angle)\n",
    "\n",
    "                if mode:\n",
    "                    img = rotate_opencv(img, nose, angle)\n",
    "                else:\n",
    "                    img = Image.fromarray(img)\n",
    "                    img = np.array(img.rotate(angle))\n",
    "            if show:\n",
    "                show_img(img)\n",
    "            return img\n",
    "        else:\n",
    "            return img\n",
    "\n",
    "\n",
    "    def rotation_detection_opencv(img, mode, show=False):\n",
    "        nose_cascade = cv2.CascadeClassifier('haarcascade_mcs_nose.xml')\n",
    "        eyes_cascade = cv2.CascadeClassifier('haarcascade_eye.xml')\n",
    "        fase_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "        nose_rects = nose_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "        eyes_rects = eyes_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "        face_rects = fase_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "        length_eyes = len(eyes_rects)\n",
    "\n",
    "        if length_eyes == 2 and len(nose_rects) != 0 and len(face_rects) != 0:\n",
    "            nose, right_eye, left_eye = get_eyes_nose(eyes_rects, nose_rects)\n",
    "        else:\n",
    "            print(\"Couldn't determine eyes/nose\")\n",
    "            return img\n",
    "        center_of_forehead = (int((right_eye[0] + left_eye[0]) / 2), int((right_eye[1] + left_eye[1]) / 2))\n",
    "        center_pred = (int((face_rects[0][0] + face_rects[0][2]) / 2), int((face_rects[0][1] + face_rects[0][1]) / 2))\n",
    "        length_line1 = distance(center_of_forehead, nose)\n",
    "        length_line2 = distance(center_pred, nose)\n",
    "        length_line3 = distance(center_pred, center_of_forehead)\n",
    "        cos_a = cosine_formula(length_line1, length_line2, length_line3)\n",
    "        angle = np.arccos(cos_a)\n",
    "        rotated_point = rotate_point(nose, center_of_forehead, angle)\n",
    "        rotated_point = (int(rotated_point[0]), int(rotated_point[1]))\n",
    "        if is_between(nose, center_of_forehead, center_pred, rotated_point):\n",
    "            angle = np.degrees(-angle)\n",
    "        else:\n",
    "            angle = np.degrees(angle)\n",
    "        if mode:\n",
    "            img = rotate_opencv(img, nose, angle)\n",
    "        else:\n",
    "            img = Image.fromarray(img)\n",
    "            img = np.array(img.rotate(angle))\n",
    "        if show:\n",
    "            show_img(img)\n",
    "        return img\n",
    "\n",
    "\n",
    "    def save_img(path, img):\n",
    "        cv2.imwrite(path, img)\n",
    "\n",
    "\n",
    "    def face_alignment(\n",
    "        path_to_load:str,\n",
    "        mode:int = 1\n",
    "        )->cv2.typing.MatLike:\n",
    "        \"\"\"Align FAces\n",
    "\n",
    "        Args:\n",
    "            path_to_load (str): path to load.\n",
    "            mode (int, optional): 0 for Cv2\n",
    "                                1 for dlib. Defaults to 1.\n",
    "\n",
    "        Returns:\n",
    "            cv2.typing.MatLike: _description_\n",
    "        \"\"\"\n",
    "        img = load_img(path_to_load)\n",
    "        if mode == 0:\n",
    "            img = rotation_detection_opencv(img, 0)\n",
    "        else:\n",
    "            img = rotation_detection_dlib(img, 0, False)\n",
    "        return img\n",
    "\n",
    "\n",
    "    class FaceCluster:\n",
    "\n",
    "        def __init__(\n",
    "            self,\n",
    "            jobs: int = 1,\n",
    "            metric: str = \"euclidean\",\n",
    "            # save: bool = False,\n",
    "            show: bool = False,\n",
    "        ) -> None:\n",
    "            \"\"\"\n",
    "            Initialize the FaceCluster object.\n",
    "\n",
    "            Parameters:\n",
    "            - jobs (int): Number of parallel jobs to run for DBSCAN (default is 1).\n",
    "            - metric (str): Metric used for clustering (default is 'euclidean').\n",
    "            - save (bool): Whether to save the clustered images (default is False).\n",
    "            - show (bool): Whether to display the clustered faces montage (default is False).\n",
    "\n",
    "            Returns:\n",
    "            - None\n",
    "            \"\"\"\n",
    "            self.metric = metric\n",
    "            self.clt = DBSCAN(metric=self.metric, n_jobs=jobs)\n",
    "            # self.save = save\n",
    "            self.show = show\n",
    "\n",
    "        def rotate_opencv(\n",
    "            self, img: cv2.typing.MatLike, nose_center: tuple, angle: float\n",
    "        ) -> cv2.typing.MatLike:\n",
    "            \"\"\"\n",
    "            Rotate an image using OpenCV.\n",
    "\n",
    "            Parameters:\n",
    "            - img (cv2.typing.MatLike): Input image.\n",
    "            - nose_center (tuple): Coordinates of the nose center.\n",
    "            - angle (float): Rotation angle.\n",
    "\n",
    "            Returns:\n",
    "            - cv2.typing.MatLike: Rotated image.\n",
    "            \"\"\"\n",
    "            M = cv2.getRotationMatrix2D(nose_center, angle, 1)\n",
    "            rotated = cv2.warpAffine(\n",
    "                img, M, (img.shape[1], img.shape[0]), flags=cv2.INTER_CUBIC\n",
    "            )\n",
    "            return rotated\n",
    "\n",
    "        def is_between(\n",
    "            self, point1: tuple, point2: tuple, point3: tuple, extra_point: tuple\n",
    "        ) -> bool:\n",
    "            \"\"\"\n",
    "            Check if extra_point lies between point1, point2, and point3.\n",
    "\n",
    "            Parameters:\n",
    "            - point1 (tuple): Coordinates of the first point.\n",
    "            - point2 (tuple): Coordinates of the second point.\n",
    "            - point3 (tuple): Coordinates of the third point.\n",
    "            - extra_point (tuple): Coordinates of the extra point.\n",
    "\n",
    "            Returns:\n",
    "            - bool: True if extra_point is between the three points, False otherwise.\n",
    "            \"\"\"\n",
    "            c1 = (point2[0] - point1[0]) * (extra_point[1] - point1[1]) - (\n",
    "                point2[1] - point1[1]\n",
    "            ) * (extra_point[0] - point1[0])\n",
    "            c2 = (point3[0] - point2[0]) * (extra_point[1] - point2[1]) - (\n",
    "                point3[1] - point2[1]\n",
    "            ) * (extra_point[0] - point2[0])\n",
    "            c3 = (point1[0] - point3[0]) * (extra_point[1] - point3[1]) - (\n",
    "                point1[1] - point3[1]\n",
    "            ) * (extra_point[0] - point3[0])\n",
    "            if (c1 < 0 and c2 < 0 and c3 < 0) or (c1 > 0 and c2 > 0 and c3 > 0):\n",
    "                return True\n",
    "            else:\n",
    "                return False\n",
    "\n",
    "        def rotate_point(self, origin: tuple, point: tuple, angle: float) -> tuple:\n",
    "            \"\"\"\n",
    "            Rotate a point around an origin by a specified angle.\n",
    "\n",
    "            Parameters:\n",
    "            - origin (tuple): Coordinates of the origin.\n",
    "            - point (tuple): Coordinates of the point to be rotated.\n",
    "            - angle (float): Rotation angle.\n",
    "\n",
    "            Returns:\n",
    "            - tuple: Coordinates of the rotated point.\n",
    "            \"\"\"\n",
    "            ox, oy = origin\n",
    "            px, py = point\n",
    "\n",
    "            qx = ox + np.cos(angle) * (px - ox) - np.sin(angle) * (py - oy)\n",
    "            qy = oy + np.sin(angle) * (px - ox) + np.cos(angle) * (py - oy)\n",
    "            return qx, qy\n",
    "\n",
    "        def cosine_formula(\n",
    "            self, length_line1: float, length_line2: float, length_line3: float\n",
    "        ) -> float:\n",
    "            \"\"\"\n",
    "            Compute the cosine of an angle using the cosine formula.\n",
    "\n",
    "            Parameters:\n",
    "            - length_line1 (float): Length of the first line.\n",
    "            - length_line2 (float): Length of the second line.\n",
    "            - length_line3 (float): Length of the third line.\n",
    "\n",
    "            Returns:\n",
    "            - float: Cosine of the angle.\n",
    "            \"\"\"\n",
    "            cos_a = -(length_line3**2 - length_line2**2 - length_line1**2) / (\n",
    "                2 * length_line2 * length_line1\n",
    "            )\n",
    "            return cos_a\n",
    "\n",
    "        def distance(self, a: tuple, b: tuple) -> float:\n",
    "            \"\"\"\n",
    "            Calculate the Euclidean distance between two points.\n",
    "\n",
    "            Parameters:\n",
    "            - a (tuple): Coordinates of the first point.\n",
    "            - b (tuple): Coordinates of the second point.\n",
    "\n",
    "            Returns:\n",
    "            - float: Euclidean distance between the two points.\n",
    "            \"\"\"\n",
    "            return np.sqrt((a[0] - b[0]) ** 2 + (a[1] - b[1]) ** 2)\n",
    "\n",
    "        def get_eyes_nose_dlib(self, shape: dlib.full_object_detection) -> tuple:  # type: ignore\n",
    "            \"\"\"\n",
    "            Extract coordinates of nose, left eye, and right eye from dlib shape object.\n",
    "\n",
    "            Parameters:\n",
    "            - shape (dlib.full_object_detection): Detected facial landmarks.\n",
    "\n",
    "            Returns:\n",
    "            - tuple: Tuple containing coordinates of nose, left eye, and right eye.\n",
    "            \"\"\"\n",
    "            nose = shape[4][1]\n",
    "            left_eye_x = int(shape[3][1][0] + shape[2][1][0]) // 2\n",
    "            left_eye_y = int(shape[3][1][1] + shape[2][1][1]) // 2\n",
    "            right_eyes_x = int(shape[1][1][0] + shape[0][1][0]) // 2\n",
    "            right_eyes_y = int(shape[1][1][1] + shape[0][1][1]) // 2\n",
    "\n",
    "            return nose, (left_eye_x, left_eye_y), (right_eyes_x, right_eyes_y)\n",
    "\n",
    "        def shape_to_normal(self, shape: dlib.full_object_detection) -> list:  # type: ignore\n",
    "            \"\"\"\n",
    "            Convert dlib shape object to a list of tuples.\n",
    "\n",
    "            Parameters:\n",
    "            - shape (dlib.full_object_detection): Detected facial landmarks.\n",
    "\n",
    "            Returns:\n",
    "            - list: List of tuples representing coordinates of facial landmarks.\n",
    "            \"\"\"\n",
    "            shape_normal = []\n",
    "            for i in range(0, 5):\n",
    "                shape_normal.append((i, (shape.part(i).x, shape.part(i).y)))\n",
    "            return shape_normal\n",
    "\n",
    "        def rotation_detection_dlib(\n",
    "            self, img: cv2.typing.MatLike, mode: int, show: bool = False\n",
    "        ) -> cv2.typing.MatLike:\n",
    "            \"\"\"\n",
    "            Perform rotation detection using dlib's facial landmarks.\n",
    "\n",
    "            Parameters:\n",
    "            - img (cv2.typing.MatLike): Input image.\n",
    "            - mode (int): Rotation mode (0: no rotation, 1: rotate).\n",
    "            - show (bool): Whether to display the rotated image (default is False).\n",
    "\n",
    "            Returns:\n",
    "            - cv2\n",
    "            \"\"\"\n",
    "            detector = dlib.get_frontal_face_detector()  # type: ignore\n",
    "            predictor = dlib.shape_predictor(\"shape_predictor_5_face_landmarks.dat\")  # type: ignore\n",
    "            gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "            rects = detector(gray, 0)\n",
    "            if len(rects) > 0:\n",
    "                for rect in rects:\n",
    "                    x = rect.left()\n",
    "                    y = rect.top()\n",
    "                    w = rect.right()\n",
    "                    h = rect.bottom()\n",
    "                    shape = predictor(gray, rect)\n",
    "                    shape = self.shape_to_normal(shape)\n",
    "                    nose, left_eye, right_eye = self.get_eyes_nose_dlib(shape)\n",
    "                    center_of_forehead = (\n",
    "                        (left_eye[0] + right_eye[0]) // 2,\n",
    "                        (left_eye[1] + right_eye[1]) // 2,\n",
    "                    )\n",
    "                    center_pred = (int((x + w) / 2), int((y + h) / 2))\n",
    "                    length_line1 = self.distance(center_of_forehead, nose)\n",
    "                    length_line2 = self.distance(center_pred, nose)\n",
    "                    length_line3 = self.distance(center_pred, center_of_forehead)\n",
    "                    cos_a = self.cosine_formula(length_line1, length_line2, length_line3)\n",
    "                    angle = np.arccos(cos_a)\n",
    "                    rotated_point = self.rotate_point(nose, center_of_forehead, angle)\n",
    "                    rotated_point = (int(rotated_point[0]), int(rotated_point[1]))\n",
    "                    if self.is_between(\n",
    "                        nose, center_of_forehead, center_pred, rotated_point\n",
    "                    ):\n",
    "                        angle = np.degrees(-angle)\n",
    "                    else:\n",
    "                        angle = np.degrees(angle)\n",
    "\n",
    "                    if mode:\n",
    "                        img = self.rotate_opencv(img, nose, angle)\n",
    "                    else:\n",
    "                        img = Image.fromarray(img)  # type: ignore\n",
    "                        img = np.array(img.rotate(angle))  # type: ignore\n",
    "                if show:\n",
    "                    show_img(img)\n",
    "                return img\n",
    "            else:\n",
    "                return img\n",
    "\n",
    "        def face_align(\n",
    "            self, imagePath: str, mode: int = 0, show: bool = False\n",
    "        ) -> cv2.typing.MatLike:\n",
    "            \"\"\"\n",
    "            Perform face alignment using rotation detection.\n",
    "\n",
    "            Parameters:\n",
    "            - imagePath (str): Path to the input image.\n",
    "            - mode (int): Rotation mode (0: no rotation, 1: rotate).\n",
    "            - show (bool): Whether to display the aligned image (default is False).\n",
    "\n",
    "            Returns:\n",
    "            - cv2.typing.MatLike: Aligned face image.\n",
    "            \"\"\"\n",
    "            img = load_img(imagePath)\n",
    "            img_rot = self.rotation_detection_dlib(img, mode, show)\n",
    "            return img_rot\n",
    "\n",
    "        def face_align_df(\n",
    "            self, imagePath: str, mode: int = 0, show: bool = False\n",
    "        ) -> cv2.typing.MatLike | None:\n",
    "            \"\"\"\n",
    "            Perform face alignment using rotation detection.\n",
    "\n",
    "            Parameters:\n",
    "            - imagePath (str): Path to the input image.\n",
    "            - mode (int): Rotation mode (0: no rotation, 1: rotate).\n",
    "            - show (bool): Whether to display the aligned image (default is False).\n",
    "\n",
    "            Returns:\n",
    "            - cv2.typing.MatLike: Aligned face image.\n",
    "            \"\"\"\n",
    "            try:\n",
    "                response = requests.get(imagePath)\n",
    "\n",
    "                if response.status_code == 200:\n",
    "                    image_array = np.frombuffer(response.content, dtype=np.uint8)\n",
    "                    image = cv2.imdecode(image_array, cv2.IMREAD_COLOR)\n",
    "                    # img = cv2.imread(imagePath)\n",
    "                    img_rot = self.rotation_detection_dlib(image, mode, show)\n",
    "                    return img_rot\n",
    "                else:\n",
    "                    logger.debug(\n",
    "                        \"Failed to fetch the image. Status code:\", response.status_code\n",
    "                    )\n",
    "            except Exception as e:\n",
    "                logger.debug(\"An error occurred:\", str(e))\n",
    "\n",
    "        def getEncodings(self, dataset: str, detection_method: str = \"cnn\") -> list | None:\n",
    "            \"\"\"\n",
    "            Extract facial encodings from a dataset of images.\n",
    "\n",
    "            Parameters:\n",
    "            - dataset (str): Path to the dataset directory.\n",
    "            - detection_method (str): Face detection method (default is \"cnn\").\n",
    "\n",
    "            Returns:\n",
    "            - list: List of dictionaries containing image information and encodings.\n",
    "            \"\"\"\n",
    "            logger.info(\"Quantifying faces...\")\n",
    "            try:\n",
    "                imagePaths = list(paths.list_images(dataset))\n",
    "                logger.debug(f\"Images loaded: {len(imagePaths)}\")\n",
    "\n",
    "                data = []\n",
    "\n",
    "                for i, imagePath in enumerate(imagePaths):\n",
    "\n",
    "                    # aligned_img_path = os.path.join(os.getcwd(),\"Temp\",os.path.basename(imagePath))\n",
    "                    # logger.debug(aligned_img_path)\n",
    "                    logger.debug(\"Processing image {}/{}\".format(i + 1, len(imagePaths)))\n",
    "                    logger.debug(imagePath)\n",
    "\n",
    "                    image_ip = self.face_align(imagePath)\n",
    "                    # cv2.imwrite(aligned_img_path, image_ip)\n",
    "                    image_ = cv2.cvtColor(image_ip, cv2.COLOR_BGR2GRAY)\n",
    "                    image = cv2.cvtColor(image_, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "                    boxes = face_recognition.face_locations(image, model=detection_method)\n",
    "\n",
    "                    encodings = face_recognition.face_encodings(image, boxes)\n",
    "\n",
    "                    d = [\n",
    "                        {\n",
    "                            # \"coorectedImagePath\":aligned_img_path,\n",
    "                            \"imagePath\": imagePath,\n",
    "                            \"id\": os.path.basename(imagePath)[:-4],\n",
    "                            \"loc\": box,\n",
    "                            \"encoding\": enc,\n",
    "                        }\n",
    "                        for (box, enc) in zip(boxes, encodings)\n",
    "                    ]\n",
    "\n",
    "                    data.extend(d)\n",
    "\n",
    "                logger.debug(\"serializing encodings...\")\n",
    "                return data  # type: ignore\n",
    "\n",
    "            except Exception as e:\n",
    "                logger.critical(f\"An error occurred: {str(e)}\")\n",
    "\n",
    "        def getEncodingsFromDf(\n",
    "            self, dataset: DataFrame, detection_method: str = \"cnn\"\n",
    "        ) -> list | None:\n",
    "            \"\"\"\n",
    "            Extract facial encodings from a dataset of images.\n",
    "\n",
    "            Parameters:\n",
    "            - dataset (df): Path to the dataset directory.\n",
    "            - detection_method (str): Face detection method (default is \"cnn\").\n",
    "\n",
    "            Returns:\n",
    "            - list: List of dictionaries containing image information and encodings.\n",
    "            \"\"\"\n",
    "            logger.info(\"Quantifying faces...\")\n",
    "            try:\n",
    "                imagePaths = dataset[\"gcsUrl\"].to_list()\n",
    "                logger.debug(f\"Images loaded: {len(imagePaths)}\")\n",
    "\n",
    "                data = []\n",
    "\n",
    "                for i, imagePath in enumerate(imagePaths):\n",
    "                    logger.debug(\"Processing image {}/{}\".format(i + 1, len(imagePaths)))\n",
    "                    logger.debug(imagePath)\n",
    "\n",
    "                    image = self.face_align_df(imagePath)\n",
    "                    try:\n",
    "                        boxes = face_recognition.face_locations(image, model=detection_method)\n",
    "\n",
    "                        encodings = face_recognition.face_encodings(image, boxes)\n",
    "\n",
    "                        d = [\n",
    "                            {\n",
    "                                \"imagePath\": imagePath,\n",
    "                                \"id\": os.path.basename(imagePath)[:-4],\n",
    "                                \"loc\": box,\n",
    "                                \"encoding\": enc,\n",
    "                            }\n",
    "                            for (box, enc) in zip(boxes, encodings)\n",
    "                        ]\n",
    "\n",
    "                        data.extend(d)\n",
    "                    except Exception as e:\n",
    "                        logger.critical(f\"An error occurred: {str(e)}\")\n",
    "                        continue\n",
    "\n",
    "                logger.debug(\"serializing encodings...\")\n",
    "                return data  # type: ignore\n",
    "\n",
    "            except Exception as e:\n",
    "                logger.critical(f\"An error occurred: {str(e)}\")\n",
    "\n",
    "        def getClusters(self, dataset: str | DataFrame) -> dict | None:\n",
    "            \"\"\"\n",
    "            Perform face clustering on a dataset and return the clustered results.\n",
    "\n",
    "            Parameters:\n",
    "            - dataset (str): Path to the dataset directory.\n",
    "\n",
    "            Returns:\n",
    "            - dict: Dictionary containing clustered face IDs.\n",
    "            \"\"\"\n",
    "            logger.debug(type(dataset))\n",
    "            if type(dataset) == str:\n",
    "                self.encodings = self.getEncodings(dataset=dataset)\n",
    "                logger.info(\"Received local filesystem dataset.\")\n",
    "            elif type(dataset) == DataFrame:\n",
    "                self.encodings = self.getEncodingsFromDf(dataset=dataset)\n",
    "                logger.info(\"Received df dataset.\")\n",
    "            try:\n",
    "                logger.info(\"Loading encodings...\")\n",
    "                data = self.encodings\n",
    "                encodings = [d[\"encoding\"] for d in data]  # type:ignore\n",
    "\n",
    "                logger.info(\"Clustering ...\")\n",
    "\n",
    "                self.clt.fit(encodings)  # type: ignore\n",
    "\n",
    "                labelIDs = np.unique(self.clt.labels_)\n",
    "\n",
    "                self.numUniqueFaces = len(np.where(labelIDs > -1)[0])\n",
    "                logger.info(\"# unique faces: {}\".format(self.numUniqueFaces))\n",
    "\n",
    "                res_dict = {}\n",
    "\n",
    "                for labelID in labelIDs:\n",
    "                    logger.info(\"Faces for face ID: {}\".format(labelID))\n",
    "                    idxs = np.where(self.clt.labels_ == labelID)[0]\n",
    "                    idxs = np.random.choice(idxs, size=min(25, len(idxs)), replace=False)\n",
    "                    logger.debug(self.clt.labels_)\n",
    "\n",
    "                    faces = []\n",
    "\n",
    "                    ids = []\n",
    "                    for i in idxs:\n",
    "                        # image = cv2.imread(data[i][\"imagePath\"])  # type:ignore\n",
    "\n",
    "                        ids.append(data[i][\"id\"])  # type:ignore\n",
    "                        # top, right, bottom, left = data[i][\"loc\"]  # type:ignore\n",
    "                        # face = image[top:bottom, left:right]\n",
    "\n",
    "                        # if self.save:\n",
    "                        #     move_image(image, i, labelID)\n",
    "\n",
    "                        # face = cv2.resize(face, (96, 96))\n",
    "                        # faces.append(face)\n",
    "\n",
    "                    res_dict[str(labelID)] = ids\n",
    "\n",
    "                    # if self.save:\n",
    "                    #     montage = build_montages(faces, (96, 96), (5, 5))[0]\n",
    "                    #     title = \"Face ID #{}\".format(labelID)\n",
    "                    #     title = \"Unknown Faces\" if labelID == -1 else title\n",
    "\n",
    "                    #     if self.show:\n",
    "                    #         cv2.imshow(title, montage)\n",
    "                    #         cv2.waitKey(0)\n",
    "                    #     cv2.imwrite(os.path.join(os.getcwd(), title + \".jpg\"), montage)\n",
    "\n",
    "                return res_dict\n",
    "\n",
    "            except Exception as e:\n",
    "                traceback_str = traceback.format_exc()\n",
    "                logger.critical(f\"An error occurred: {str(e)}. {traceback_str}\")\n",
    "        \n",
    "    storage_client = storage.Client(\"plenary-truck-411220\")\n",
    "\n",
    "    bucket_pipeline = storage_client.get_bucket(\"faces_for_clustersdetection_pipeline\")\n",
    "    # Create a blob object from the filepath\n",
    "    blob = bucket_pipeline.blob(\"keys/detectionKey.json\")\n",
    "    face_landmarks = bucket_pipeline.blob(\"shape_predictor_5_face_landmarks.dat\")\n",
    "    # Download the file to a destination\n",
    "    blob.download_to_filename(\"detectionKey.json\")\n",
    "    face_landmarks.download_to_filename(\"shape_predictor_5_face_landmarks.dat\")\n",
    "    CLOUD_CRED = \"detectionKey.json\"\n",
    "    client = bigquery.Client.from_service_account_json(CLOUD_CRED)\n",
    "\n",
    "    sql_query = \"\"\"\n",
    "        SELECT * FROM `plenary-truck-411220.clustering_dataset.faces`\n",
    "        \"\"\"\n",
    "    df = client.query(sql_query).result().to_dataframe()\n",
    "    data = FaceCluster()\n",
    "    res = data.getClusters(dataset=df)\n",
    "\n",
    "    res_exists = res != None\n",
    "    if res_exists:\n",
    "        for cluster_id in res.keys():\n",
    "            if (cluster_id != '-1'):\n",
    "                update_query = f\"\"\"\n",
    "                    UPDATE `plenary-truck-411220.clustering_dataset.faces` SET cluster={int(cluster_id)}\n",
    "                    WHERE markedId IN {tuple(res[cluster_id])}\n",
    "                \"\"\"\n",
    "                client.query(update_query)   \n",
    "\n",
    "    return res_exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "@component(base_image=\"python:3.10\", packages_to_install=[\"numpy==1.23.5\", \"opencv-contrib-python-headless==4.9.0.80\", \"imutils==0.5.4\", \"db-dtypes==1.2.0\", \"pillow==10.2.0\", \"build==1.0.3\", \"cmake==3.28.3\", \"dlib==19.24.2\", \"face-recognition==1.3.0\", \"logger==1.4\", \"requests==2.31.0\", \"pandas==2.2.0\", \"google-cloud-storage==2.14.0\", \"google-cloud-bigquery==3.17.2\", \"kfp==2.6.0\"])\n",
    "def classify_images(prev_task: bool):\n",
    "    from google.cloud import storage, bigquery\n",
    "    import face_recognition\n",
    "    import os\n",
    "    from PIL import Image\n",
    "    import requests\n",
    "    import logging\n",
    "    import tempfile\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "\n",
    "    logging.basicConfig(level=logging.DEBUG)\n",
    "\n",
    "    logger = logging.getLogger(__name__)\n",
    "\n",
    "    if prev_task:\n",
    "        storage_client = storage.Client(\"plenary-truck-411220\")\n",
    "\n",
    "        bucket_pipeline = storage_client.get_bucket(\"faces_for_clustersdetection_pipeline\")\n",
    "        # Create a blob object from the filepath\n",
    "        blob = bucket_pipeline.blob(\"keys/detectionKey.json\")\n",
    "        # Download the file to a destination\n",
    "        blob.download_to_filename(\"detectionKey.json\")\n",
    "        CLOUD_CRED = \"detectionKey.json\"\n",
    "        os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = CLOUD_CRED\n",
    "        sql_query = \"\"\"\n",
    "            SELECT * FROM `plenary-truck-411220.clustering_dataset.faces`\n",
    "        \"\"\"\n",
    "        client = bigquery.Client()\n",
    "        df = client.query(sql_query).result().to_dataframe().fillna(-1)\n",
    "        unique_clusters = df['cluster'].unique().tolist()\n",
    "        clusters = {str(key): [] for key in unique_clusters}\n",
    "\n",
    "        with tempfile.TemporaryDirectory() as tempDir:\n",
    "            logger.debug(\"Iterating through the table . . .\")\n",
    "            for _, row in df.iterrows():\n",
    "                img = Image.open(requests.get(row['gcsUrl'], stream=True).raw)\n",
    "                id = row[\"markedId\"]\n",
    "                img.save(os.path.join(tempDir, f\"{id}.png\"))\n",
    "                img_path = os.path.join(tempDir, f\"{id}.png\")\n",
    "                clusters[str(row['cluster'])].append([id, img_path])\n",
    "                known_encodings = {str(key): [] for key in unique_clusters}\n",
    "                for key in clusters.keys():\n",
    "                    if key != \"-1\":\n",
    "                        for imgs in clusters[key]:\n",
    "                            known_img = face_recognition.load_image_file(imgs[1])\n",
    "                            encodings = face_recognition.face_encodings(known_img, num_jitters=2)[0]\n",
    "                            known_encodings[key].append(encodings)\n",
    "                        logger.debug(f\"Encoding created for {key} . . .\")\n",
    "                \n",
    "                for uncl in clusters[\"-1\"]:\n",
    "                    unknown_img = face_recognition.load_image_file(uncl[1])\n",
    "                    encoding_uk = face_recognition.face_encodings(unknown_img)\n",
    "\n",
    "                    logger.debug(f\"Checking for IMG {uncl[0]}\")\n",
    "\n",
    "                    if len(encoding_uk) > 0:\n",
    "                        encoding_uk = encoding_uk[0]\n",
    "                    else:\n",
    "                        continue\n",
    "\n",
    "                    for key in known_encodings.keys():\n",
    "                        res = face_recognition.compare_faces(known_encodings[key], encoding_uk, tolerance=0.4)\n",
    "                        logger.info(res)\n",
    "                        if any(res):\n",
    "                            client.query(f\"UPDATE `plenary-truck-411220.clustering_dataset.faces` SET cluster={int(key)} WHERE markedId={uncl[0]}\")\n",
    "                            logger.debug(f\"Added to CLUSTER {key}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "@pipeline(name=\"clustering_classification_pipeline\", pipeline_root=PIPELINE_ROOT + \"detection_pipeline\")\n",
    "def detection_pipeline():\n",
    "    clustering_task = (fetch_cropped_imgs_and_clustering()).set_memory_limit('64G')\n",
    "    classification_task = classify_images(prev_task = clustering_task.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "compiler.Compiler().compile(\n",
    "    pipeline_func=detection_pipeline, package_path=\"clus_class_pipeline.yaml\" # type: ignore\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "job = aiplatform.PipelineJob(\n",
    "    display_name=\"clustering_classification_pipeline\",\n",
    "    template_path=\"./clus_class_pipeline.yaml\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job.submit(\n",
    "    service_account=\"detection@plenary-truck-411220.iam.gserviceaccount.com\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
